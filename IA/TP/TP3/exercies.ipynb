{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "Ce perceptron calcul la fonction  $f: x \\rightarrow a\\times x + b$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Perceptron(\n  (fc1): Linear(in_features=10, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "net = Perceptron()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayeredPerceptron(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(MultiLayeredPerceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, 5)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MultiLayeredPerceptron(\n  (fc1): Linear(in_features=100, out_features=50, bias=True)\n  (fc2): Linear(in_features=50, out_features=25, bias=True)\n  (fc3): Linear(in_features=25, out_features=5, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "net = MultiLayeredPerceptron()\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "Ce réseau calcul une fonction un poil plus compliquée que précédemment. \n",
    "Soit $f_{1} : x \\rightarrow w_{1}*x$, $f_{2} : x \\rightarrow w_{2}*x$,$f_{1} : x \\rightarrow w_{2}*x$, alors le réseau calcul $f_{3}(f_{2}(f_{1}(x)))$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearMultiLayeredPerceptron(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(NonLinearMultiLayeredPerceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(50, 100)\n",
    "        self.fc2 = nn.Linear(100, 500)\n",
    "        self.fc3 = nn.Linear(500, 10)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NonLinearMultiLayeredPerceptron(\n  (fc1): Linear(in_features=100, out_features=50, bias=True)\n  (fc2): Linear(in_features=50, out_features=25, bias=True)\n  (fc3): Linear(in_features=25, out_features=2, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "net = NonLinearMultiLayeredPerceptron()\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "On a un neurone par output puisqu'un neurone ne donne qu'une seule valeur, l'image par sa fonction. La fonction *softmax* permet d'apprendre très vite grâce à son fort gradient. Permettant d'éviter la disparition du gradient. De plus la fonction *max* n'est pas dérivable. De plus le softmax permet d'obtenir une probabilité pour chacune des valeurs contrairement au max. De plus le softmax permet d'amplifier les valeurs élevée en écrasant les valeurs les plus faibles sans pour autant les détruire. Pour ne pas que ça explose on va normaliser, on obtien donc une fonction de probabilité en sortie. \n",
    " - dérivable\n",
    " - amplifie les valeurs élevées\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "L'architecture ne fais pas tout! LOSS ! L'entropie croisée mesure la dissimilarité. Faible quand les distribution sont proches, élevées quand les distributions sont éloignées. Plus de sens ici en terme statistique.\n",
    "On calcul la perte d'information fait par notre model sur les données. \n",
    "Théorème d'approximation universelle. Les couches cachées ne servents à rien... Une seule couche cachée pour approcher n'importe quelle fonction. Taille de cette couche? Exponentielle par rapoort au nombre de couches qu'on veut utiliser. \n",
    "\n",
    "> Conséquence : augmentation égale du nb de paramètre, augmenter le nb de couches plutôt que d'augmenter la taille d'une couche intermédiaire\n",
    "\n",
    "Avoir un nombre de paramètre raisonable par rapport au nombre de données. Les conv permettent de garder la même puissance d'analyse de donnée.\n",
    "\n",
    "- Idée cléf de la convolution : conv enter noyau et image en entrée. On peut le voir comme un partage des paramètre. On le balaye sur toute l'image. On va pouvoir apprendre à détecter des chatons en haut et en bas à droite. \n",
    "\n",
    "Le detecteur élémentaire de forme, est appris en utilisant les infos partout ou elle s'active. On ne peut pas le faire avec une couche dense, elle ne regarde que de façon globale. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}